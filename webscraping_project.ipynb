{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools for Big Data: Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = []\n",
    "\n",
    "url1 = [\n",
    "    'https://books.toscrape.com/catalogue/category/books/health_47/index.html',\n",
    "    'https://books.toscrape.com/catalogue/category/books/science-fiction_16/index.html',\n",
    "    'https://books.toscrape.com/catalogue/category/books/humor_30/index.html',\n",
    "    'https://books.toscrape.com/catalogue/category/books/classics_6/index.html',\n",
    "    'https://books.toscrape.com/catalogue/category/books/philosophy_7/index.html'\n",
    "]\n",
    "#Webscraper for the books \n",
    "for url in url1:\n",
    "    response1 = requests.get(url)\n",
    "    soup1 = BeautifulSoup(response1.text, 'html.parser')\n",
    "    books = soup1.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "    for book in books:\n",
    "        title = book.h3.a[\"title\"]\n",
    "        price = book.find(\"p\", class_=\"price_color\").text[2:]\n",
    "        rating = book.p[\"class\"][1]\n",
    "        stock = book.find(\"p\", class_=\"instock availability\").get_text().strip()\n",
    "        category = url.split('/')[-2]\n",
    "        image = url.replace(\"index.html\", \"\") + book.find(\"img\").get(\"src\")\n",
    "\n",
    "        # Extracting the URL for each book\n",
    "        book_url = url.replace(\"index.html\", \"\") + book.h3.a[\"href\"]\n",
    "\n",
    "        # Requesting the individual book page\n",
    "        response_book = requests.get(book_url)\n",
    "        soup_book = BeautifulSoup(response_book.text, 'html.parser')\n",
    "\n",
    "        # Webscraping the description \n",
    "        description = soup_book.find_all('article', attrs={\"class\": \"product_page\"})[0].find_all('p')[3].get_text(strip=True)\n",
    "\n",
    "        book_data.append({\n",
    "            'Title': title,\n",
    "            'Price': price,\n",
    "            'Rating': rating,\n",
    "            'Availability': stock,\n",
    "            'Description': description,\n",
    "            'Category': category,\n",
    "            'Image Url': image\n",
    "        })\n",
    "\n",
    "# Creating a DataFrame from the collected data\n",
    "books_df = pd.DataFrame(book_data)\n",
    "\n",
    "#Saving the dataframe to a CSV file\n",
    "books_df.to_csv('books_data.csv', index= False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
